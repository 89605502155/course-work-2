{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gzip import open # NB: overrides standard open()\n",
    "import pickle as pkl\n",
    "import tensorly as tl\n",
    "from tensorly.base import tensor_to_vec,  partial_tensor_to_vec\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "warnings.simplefilter('ignore') # отключим предупреждения Anaconda\n",
    "Xdata_numpy = pkl.load(open('C:/Users/admin/Desktop/88/X.pkl.gz', 'rb'))\n",
    "Ydata = pkl.load(open('C:/Users/admin/Desktop/88/y.pkl.gz', 'rb'))\n",
    "\n",
    "print(type(Xdata_numpy[\"X\"]))\n",
    "\n",
    "#делим набор на обучающий и тестовый\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     Xdata_numpy[\"X\"], Ydata, test_size=0.2856 \n",
    ")\n",
    "\n",
    "print( y_train.shape)\n",
    "# прописываем класс регрессии\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorly.regression.kruskal_regression import KruskalRegressor\n",
    "\n",
    "class WrappedKruskalRegressor(BaseEstimator):\n",
    "\tdef __init__(self, weight_rank = 1, tol = 1e-6, reg_W = 1, n_iter_max = 100):\n",
    "\t\tself.weight_rank = weight_rank\n",
    "\t\tself.tol = tol\n",
    "\t\tself.reg_W = reg_W\n",
    "\t\tself.n_iter_max = n_iter_max\n",
    "\t\n",
    "\tdef fit(self, X, y = None):\n",
    "\t\tself._model = KruskalRegressor(self.weight_rank, self.tol, self.reg_W, self.n_iter_max)\n",
    "\t\tself._model.fit(X, y)\n",
    "\t\tif self._model.n_iterations_ == self.n_iter_max:\n",
    "\t\t\traise Exception('{} did not converge'.format(self))\n",
    "\t\treturn self\n",
    "\t\n",
    "\tdef predict(self, X):\n",
    "\t\treturn self._model.predict(X)\n",
    "\t\n",
    "\tdef score(self, X, y):\n",
    "\t\treturn r2_score(y, self.predict(X))\n",
    "\n",
    "\n",
    "#начинаем применять\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "regressioModel=WrappedKruskalRegressor()\n",
    "parametrsNames={'n_iter_max': [30000],\n",
    "                'reg_W': range(1,21),\n",
    "                'tol': [1e-04,1e-05,1e-06],\n",
    "                'weight_rank': range(1,21)\n",
    "               }\n",
    "\n",
    "gridCought=GridSearchCV(regressioModel, parametrsNames, cv=5)\n",
    "gridCought.fit(X_train,y_train.iloc[:,0])\n",
    "predictors=gridCought.predict(X_test)\n",
    "\n",
    "print(gridCought.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridCought.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridCought.score(X_test, y_test.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_test.iloc[:,0],y_test.iloc[:,0],color=\"blue\")\n",
    "plt.plot(y_test.iloc[:,0],predictors,\".\",color=\"red\")\n",
    "plt.xlabel(\"Истинные значения\",fontsize=12)\n",
    "plt.ylabel(\"Предсказанные значения\", fontsize=12)\n",
    "plt.grid()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridCought.scorer_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridCought.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " gridCought.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridCought.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres  = gridCought.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridCought.cv_results_['mean_test_score'][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(gridCought.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mean_score,  params  in zip(cvres [ \"mean_test_score\" ], \n",
    "                                cvres [ \"params\" ]\n",
    "                                ): \n",
    "    print (np.sqrt(mean_score**2) , params) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score=[]\n",
    "score_l=[]\n",
    "parametr_reg_w=[]\n",
    "my_error=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x,y):\n",
    "    my_error=[]\n",
    "    for i in range(0,len(y)):\n",
    "        my_error+=[(x[i]-y[i])**2]\n",
    "    return my_error\n",
    "my_error=f(np.array(y_test.iloc[:,0]),predictors)\n",
    "print(my_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mean_score,  params  in zip (cvres [ \"mean_test_score\"],cvres [ \"params\" ] )  : \n",
    "    score+=[np.array(mean_score)**2]\n",
    "    score_l+=[np.array((mean_score))]\n",
    "    parametr_reg_w+=[params[\"reg_W\"]]\n",
    "print (score,\"   \",parametr_reg_w) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(parametr_reg_w,score_l,\".\",color=\"red\")\n",
    "#plt.plot(parametr_reg_w,score_l,\".\",color=\"blue\")\n",
    "plt.grid()\n",
    "plt.ylabel(\"Ошибка\",fontsize=15)\n",
    "plt.xlabel(\"Параметр\",fontsize=15)\n",
    "plt.title(\"График зависимости квадрата ошибки от reg_W\",fontsize=18)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?file_obj.write(plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
